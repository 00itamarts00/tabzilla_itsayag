{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review errors in the results files `metadataset_errors*.csv` for GPU-algs-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>results_bucket_path</th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>alg_name</th>\n",
       "      <th>hparam_source</th>\n",
       "      <th>trial_number</th>\n",
       "      <th>alg_hparam_id</th>\n",
       "      <th>exp_name</th>\n",
       "      <th>exception</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>results/openml__APSFailure__168868/DANet/algs-...</td>\n",
       "      <td>openml__APSFailure__168868</td>\n",
       "      <td>DANet</td>\n",
       "      <td>default</td>\n",
       "      <td>0</td>\n",
       "      <td>DANet__seed_0__trial_0</td>\n",
       "      <td>algs-gpu-2-datasets-a_120622_092527_3c1c.zip</td>\n",
       "      <td>Traceback (most recent call last):\\n  File \"/h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>results/openml__APSFailure__168868/DANet/algs-...</td>\n",
       "      <td>openml__APSFailure__168868</td>\n",
       "      <td>DANet</td>\n",
       "      <td>random_1_s0</td>\n",
       "      <td>1</td>\n",
       "      <td>DANet__seed_0__trial_1</td>\n",
       "      <td>algs-gpu-2-datasets-a_120622_092527_3c1c.zip</td>\n",
       "      <td>Traceback (most recent call last):\\n  File \"/h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>results/openml__APSFailure__168868/DANet/algs-...</td>\n",
       "      <td>openml__APSFailure__168868</td>\n",
       "      <td>DANet</td>\n",
       "      <td>random_2_s0</td>\n",
       "      <td>2</td>\n",
       "      <td>DANet__seed_0__trial_2</td>\n",
       "      <td>algs-gpu-2-datasets-a_120622_092527_3c1c.zip</td>\n",
       "      <td>Traceback (most recent call last):\\n  File \"/h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>results/openml__APSFailure__168868/DANet/algs-...</td>\n",
       "      <td>openml__APSFailure__168868</td>\n",
       "      <td>DANet</td>\n",
       "      <td>random_3_s0</td>\n",
       "      <td>3</td>\n",
       "      <td>DANet__seed_0__trial_3</td>\n",
       "      <td>algs-gpu-2-datasets-a_120622_092527_3c1c.zip</td>\n",
       "      <td>Traceback (most recent call last):\\n  File \"/h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>results/openml__APSFailure__168868/DANet/algs-...</td>\n",
       "      <td>openml__APSFailure__168868</td>\n",
       "      <td>DANet</td>\n",
       "      <td>random_4_s0</td>\n",
       "      <td>4</td>\n",
       "      <td>DANet__seed_0__trial_4</td>\n",
       "      <td>algs-gpu-2-datasets-a_120622_092527_3c1c.zip</td>\n",
       "      <td>Traceback (most recent call last):\\n  File \"/h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 results_bucket_path  \\\n",
       "0  results/openml__APSFailure__168868/DANet/algs-...   \n",
       "1  results/openml__APSFailure__168868/DANet/algs-...   \n",
       "2  results/openml__APSFailure__168868/DANet/algs-...   \n",
       "3  results/openml__APSFailure__168868/DANet/algs-...   \n",
       "4  results/openml__APSFailure__168868/DANet/algs-...   \n",
       "\n",
       "                 dataset_name alg_name hparam_source  trial_number  \\\n",
       "0  openml__APSFailure__168868    DANet       default             0   \n",
       "1  openml__APSFailure__168868    DANet   random_1_s0             1   \n",
       "2  openml__APSFailure__168868    DANet   random_2_s0             2   \n",
       "3  openml__APSFailure__168868    DANet   random_3_s0             3   \n",
       "4  openml__APSFailure__168868    DANet   random_4_s0             4   \n",
       "\n",
       "            alg_hparam_id                                      exp_name  \\\n",
       "0  DANet__seed_0__trial_0  algs-gpu-2-datasets-a_120622_092527_3c1c.zip   \n",
       "1  DANet__seed_0__trial_1  algs-gpu-2-datasets-a_120622_092527_3c1c.zip   \n",
       "2  DANet__seed_0__trial_2  algs-gpu-2-datasets-a_120622_092527_3c1c.zip   \n",
       "3  DANet__seed_0__trial_3  algs-gpu-2-datasets-a_120622_092527_3c1c.zip   \n",
       "4  DANet__seed_0__trial_4  algs-gpu-2-datasets-a_120622_092527_3c1c.zip   \n",
       "\n",
       "                                           exception  \n",
       "0  Traceback (most recent call last):\\n  File \"/h...  \n",
       "1  Traceback (most recent call last):\\n  File \"/h...  \n",
       "2  Traceback (most recent call last):\\n  File \"/h...  \n",
       "3  Traceback (most recent call last):\\n  File \"/h...  \n",
       "4  Traceback (most recent call last):\\n  File \"/h...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# errors_df = pd.read_csv(\"/home/shared/tabzilla/TabSurvey/metadataset_errors.csv\")\n",
    "errors_df = pd.read_csv(\"../TabSurvey/metadataset_errors.csv\")\n",
    "\n",
    "# filter by experiment\n",
    "errors_df = errors_df.loc[errors_df[\"exp_name\"].str.contains(\"algs-gpu-2\")]\n",
    "\n",
    "errors_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "errors by dataset:\n",
      " openml__dionis__189355                                       109\n",
      "openml__sylvine__168912                                       92\n",
      "openml__sulfur__360966                                        92\n",
      "openml__walking-activity__9945                                84\n",
      "openml__skin-segmentation__9965                               82\n",
      "openml__albert__189356                                        82\n",
      "openml__Census-Income__168340                                 79\n",
      "openml__audiology__7                                          77\n",
      "openml__jungle_chess_2pcs_raw_endgame_complete__167119        74\n",
      "openml__chess__3952                                           74\n",
      "openml__Internet-Advertisements__167125                       73\n",
      "openml__kropt__2076                                           72\n",
      "openml__helena__168329                                        71\n",
      "openml__soybean__41                                           70\n",
      "openml__connect-4__146195                                     70\n",
      "openml__primary-tumor__146032                                 70\n",
      "openml__Amazon_employee_access__34539                         69\n",
      "openml__mushroom__24                                          69\n",
      "openml__covertype__7593                                       69\n",
      "openml__nursery__9892                                         69\n",
      "openml__kr-vs-kp__3                                           67\n",
      "openml__mfeat-morphological__18                               67\n",
      "openml__artificial-characters__14964                          67\n",
      "openml__car-evaluation__146192                                66\n",
      "openml__splice__45                                            64\n",
      "openml__LED-display-domain-7digit__125921                     64\n",
      "openml__car__146821                                           64\n",
      "openml__dna__167140                                           64\n",
      "openml__tic-tac-toe__49                                       64\n",
      "openml__PhishingWebsites__14952                               63\n",
      "                                                            ... \n",
      "openml__Wine__190420                                           7\n",
      "openml__cpu_small__4883                                        7\n",
      "openml__eye_movements__3897                                    7\n",
      "openml__kin8nm__2280                                           5\n",
      "openml__veteran__4828                                          5\n",
      "openml__heart-h__50                                            3\n",
      "openml__ilpd__9971                                             3\n",
      "openml__Wisconsin-breast-cancer-cytology-features__361003      3\n",
      "openml__labor__4                                               3\n",
      "openml__acute-inflammations__10089                             3\n",
      "openml__heart-c__48                                            3\n",
      "openml__dresses-sales__125920                                  3\n",
      "openml__SpeedDating__146607                                    3\n",
      "openml__autos__9                                               3\n",
      "openml__bank-marketing__9899                                   3\n",
      "openml__sick__3021                                             3\n",
      "openml__dermatology__35                                        3\n",
      "openml__chscase_foot__5012                                     2\n",
      "openml__bodyfat__5514                                          2\n",
      "openml__cmc__23                                                2\n",
      "openml__profb__3561                                            2\n",
      "openml__lymph__10                                              2\n",
      "openml__irish__3543                                            2\n",
      "openml__churn__167141                                          2\n",
      "openml__libras__360948                                         2\n",
      "openml__meta__4729                                             2\n",
      "openml__colleges__359942                                       2\n",
      "openml__dataset_sales__190418                                  2\n",
      "openml__tae__47                                                2\n",
      "openml__anneal__2867                                           1\n",
      "Name: dataset_name, Length: 182, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# how many errors by dataset?\n",
    "print(f\"errors by dataset:\\n {errors_df['dataset_name'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "errors by alg:\n",
      " rtdl_FTTransformer    4057\n",
      "TabTransformer        1686\n",
      "NODE                   516\n",
      "SAINT                  333\n",
      "DANet                  177\n",
      "STG                     90\n",
      "NAM                     74\n",
      "rtdl_ResNet             60\n",
      "DeepFM                  50\n",
      "rtdl_MLP                30\n",
      "Name: alg_name, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# by alg...\n",
    "print(f\"errors by alg:\\n {errors_df['alg_name'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "known_err_str = [\n",
    "    \"RuntimeError: CUDA out of memory.\",\n",
    "    \"CUDA error: invalid configuration argument\",\n",
    "    \"TimeoutException\",  # our timeout exception\n",
    "    \"Cannot allocate memory\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Triage errors by alg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_by_alg = {}\n",
    "for alg_name in errors_df[\"alg_name\"].unique():\n",
    "    errors_by_alg[alg_name] = errors_df.loc[errors_df[\"alg_name\"] == alg_name, \"exception\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TabTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of errors for alg TabTransformer: 1686\n",
      "number of unique errors: 109\n"
     ]
    }
   ],
   "source": [
    "alg_name = \"TabTransformer\"\n",
    "\n",
    "print(f\"number of errors for alg {alg_name}: {len(errors_by_alg[alg_name])}\")\n",
    "print(f\"number of unique errors: {len(set(errors_by_alg[alg_name]))}\")\n",
    "\n",
    "unique_errors = list(set(errors_by_alg[alg_name]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error type: RuntimeError: CUDA out of memory.\n",
      "num of unique errors with this string: 91 of 109\n",
      "error type: CUDA error: invalid configuration argument\n",
      "num of unique errors with this string: 1 of 109\n",
      "error type: TimeoutException\n",
      "num of unique errors with this string: 8 of 109\n",
      "error type: Cannot allocate memory\n",
      "num of unique errors with this string: 1 of 109\n",
      "error type: must be the same as input size\n",
      "num of unique errors with this string: 6 of 109\n",
      "error type: Dimension out of range\n",
      "num of unique errors with this string: 1 of 109\n",
      "error type: self must be a matrix\n",
      "num of unique errors with this string: 1 of 109\n"
     ]
    }
   ],
   "source": [
    "# get some known errors out of the way\n",
    "\n",
    "tmp_known_err_str = known_err_str + [\n",
    "    \"must be the same as input size\", # this is an issue with TabTransformer: https://github.com/naszilla/tabzilla/issues/78\n",
    "    \"Dimension out of range\", # another known issue with TabTransformer: https://github.com/naszilla/tabzilla/issues/77\n",
    "    \"self must be a matrix\", # another known issue with TabTransformer: https://github.com/naszilla/tabzilla/issues/79\n",
    "]\n",
    "\n",
    "for err_str in tmp_known_err_str:\n",
    "    print(f\"error type: {err_str}\")\n",
    "    print(f\"num of unique errors with this string: {len([e for e in unique_errors if err_str in e])} of {len(unique_errors)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what are the remaining errors?\n",
    "\n",
    "remaining_errors = [e for e in unique_errors if all([s not in e for s in tmp_known_err_str])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 remaining errors\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(remaining_errors)} remaining errors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of errors for alg NODE: 516\n",
      "number of unique errors: 143\n"
     ]
    }
   ],
   "source": [
    "alg_name = \"NODE\"\n",
    "\n",
    "print(f\"number of errors for alg {alg_name}: {len(errors_by_alg[alg_name])}\")\n",
    "print(f\"number of unique errors: {len(set(errors_by_alg[alg_name]))}\")\n",
    "\n",
    "unique_errors = list(set(errors_by_alg[alg_name]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error type: RuntimeError: CUDA out of memory.\n",
      "num of unique errors with this string: 134 of 143\n",
      "error type: CUDA error: invalid configuration argument\n",
      "num of unique errors with this string: 0 of 143\n",
      "error type: TimeoutException\n",
      "num of unique errors with this string: 9 of 143\n",
      "error type: Cannot allocate memory\n",
      "num of unique errors with this string: 0 of 143\n"
     ]
    }
   ],
   "source": [
    "# get some known errors out of the way\n",
    "\n",
    "for err_str in known_err_str:\n",
    "    print(f\"error type: {err_str}\")\n",
    "    print(f\"num of unique errors with this string: {len([e for e in unique_errors if err_str in e])} of {len(unique_errors)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what are the remaining errors?\n",
    "\n",
    "remaining_errors = [e for e in unique_errors if all([s not in e for s in known_err_str])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(remaining_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of errors for alg STG: 90\n",
      "number of unique errors: 10\n"
     ]
    }
   ],
   "source": [
    "alg_name = \"STG\"\n",
    "\n",
    "print(f\"number of errors for alg {alg_name}: {len(errors_by_alg[alg_name])}\")\n",
    "print(f\"number of unique errors: {len(set(errors_by_alg[alg_name]))}\")\n",
    "\n",
    "unique_errors = list(set(errors_by_alg[alg_name]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error type: RuntimeError: CUDA out of memory.\n",
      "num of unique errors with this string: 0 of 10\n",
      "error type: CUDA error: invalid configuration argument\n",
      "num of unique errors with this string: 0 of 10\n",
      "error type: TimeoutException\n",
      "num of unique errors with this string: 9 of 10\n",
      "error type: Cannot allocate memory\n",
      "num of unique errors with this string: 0 of 10\n"
     ]
    }
   ],
   "source": [
    "# get some known errors out of the way\n",
    "\n",
    "for err_str in known_err_str:\n",
    "    print(f\"error type: {err_str}\")\n",
    "    print(f\"num of unique errors with this string: {len([e for e in unique_errors if err_str in e])} of {len(unique_errors)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what are the remaining errors?\n",
    "\n",
    "remaining_errors = [e for e in unique_errors if all([s not in e for s in known_err_str])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 remaining errros\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(remaining_errors)} remaining errros\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/shared/tabzilla/TabSurvey/tabzilla_experiment.py\", line 137, in __call__\n",
      "    result = cross_validation(model, self.dataset, self.time_limit)\n",
      "  File \"/home/shared/tabzilla/TabSurvey/tabzilla_utils.py\", line 264, in cross_validation\n",
      "    scorers[\"train\"].eval(\n",
      "  File \"/home/shared/tabzilla/TabSurvey/utils/scorer.py\", line 49, in eval\n",
      "    mse = mean_squared_error(y_true, y_prediction)\n",
      "  File \"/opt/conda/envs/torch/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 442, in mean_squared_error\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"/opt/conda/envs/torch/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"/opt/conda/envs/torch/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 899, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/opt/conda/envs/torch/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 146, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(remaining_errors[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of NaN errors: 20\n",
      "algs: STG    20\n",
      "Name: alg_name, dtype: int64\n",
      "datasets: openml__chscase_foot__5012        2\n",
      "openml__EgyptianSkulls__5040      2\n",
      "openml__bodyfat__5514             2\n",
      "openml__liver-disorders__52948    2\n",
      "openml__Wine__190420              2\n",
      "openml__cpu_small__4883           2\n",
      "openml__veteran__4828             2\n",
      "openml__dataset_sales__190418     2\n",
      "openml__meta__4729                2\n",
      "openml__aloi__12732               1\n",
      "openml__mv__4774                  1\n",
      "Name: dataset_name, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "err_str = \"Input contains NaN\"\n",
    "print(f\"number of NaN errors: {len([e for e in errors_by_alg[alg_name] if err_str in e])}\")\n",
    "\n",
    "# which algs?\n",
    "print(f\"algs: {errors_df[errors_df['exception'].str.contains(err_str)]['alg_name'].value_counts()}\")\n",
    "\n",
    "# which datasets?\n",
    "print(f\"datasets: {errors_df[errors_df['exception'].str.contains(err_str)]['dataset_name'].value_counts()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of errors for alg NAM: 74\n",
      "number of unique errors: 9\n"
     ]
    }
   ],
   "source": [
    "alg_name = \"NAM\"\n",
    "\n",
    "print(f\"number of errors for alg {alg_name}: {len(errors_by_alg[alg_name])}\")\n",
    "print(f\"number of unique errors: {len(set(errors_by_alg[alg_name]))}\")\n",
    "\n",
    "unique_errors = list(set(errors_by_alg[alg_name]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error type: RuntimeError: CUDA out of memory.\n",
      "num of unique errors with this string: 0 of 9\n",
      "error type: CUDA error: invalid configuration argument\n",
      "num of unique errors with this string: 0 of 9\n",
      "error type: TimeoutException\n",
      "num of unique errors with this string: 9 of 9\n",
      "error type: Cannot allocate memory\n",
      "num of unique errors with this string: 0 of 9\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for err_str in known_err_str:\n",
    "    print(f\"error type: {err_str}\")\n",
    "    print(f\"num of unique errors with this string: {len([e for e in unique_errors if err_str in e])} of {len(unique_errors)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of errors for alg DeepFM: 50\n",
      "number of unique errors: 36\n"
     ]
    }
   ],
   "source": [
    "tmp_known_err_str = known_err_str + [\n",
    "    \"Singleton array\",  # https://github.com/naszilla/tabzilla/issues/83\n",
    "    ]\n",
    "\n",
    "alg_name = \"DeepFM\"\n",
    "\n",
    "print(f\"number of errors for alg {alg_name}: {len(errors_by_alg[alg_name])}\")\n",
    "print(f\"number of unique errors: {len(set(errors_by_alg[alg_name]))}\")\n",
    "\n",
    "unique_errors = list(set(errors_by_alg[alg_name]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error type: RuntimeError: CUDA out of memory.\n",
      "num of unique errors with this string: 0 of 36\n",
      "error type: CUDA error: invalid configuration argument\n",
      "num of unique errors with this string: 0 of 36\n",
      "error type: TimeoutException\n",
      "num of unique errors with this string: 6 of 36\n",
      "error type: Cannot allocate memory\n",
      "num of unique errors with this string: 0 of 36\n",
      "error type: Singleton array\n",
      "num of unique errors with this string: 30 of 36\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for err_str in tmp_known_err_str:\n",
    "    print(f\"error type: {err_str}\")\n",
    "    print(f\"num of unique errors with this string: {len([e for e in unique_errors if err_str in e])} of {len(unique_errors)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 remaining errros\n"
     ]
    }
   ],
   "source": [
    "# what are the remaining errors?\n",
    "\n",
    "remaining_errors = [e for e in unique_errors if all([s not in e for s in tmp_known_err_str])]\n",
    "print(f\"{len(remaining_errors)} remaining errros\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of Singleton errors: 30\n",
      "algs: DeepFM    30\n",
      "Name: alg_name, dtype: int64\n",
      "datasets: openml__sulfur__360966    30\n",
      "Name: dataset_name, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "err_str = \"Singleton array\"\n",
    "print(f\"number of Singleton errors: {len([e for e in errors_by_alg[alg_name] if err_str in e])}\")\n",
    "\n",
    "# which algs?\n",
    "print(f\"algs: {errors_df[errors_df['exception'].str.contains(err_str)]['alg_name'].value_counts()}\")\n",
    "\n",
    "# which datasets?\n",
    "print(f\"datasets: {errors_df[errors_df['exception'].str.contains(err_str)]['dataset_name'].value_counts()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAINT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of errors for alg SAINT: 333\n",
      "number of unique errors: 73\n"
     ]
    }
   ],
   "source": [
    "alg_name = \"SAINT\"\n",
    "\n",
    "print(f\"number of errors for alg {alg_name}: {len(errors_by_alg[alg_name])}\")\n",
    "print(f\"number of unique errors: {len(set(errors_by_alg[alg_name]))}\")\n",
    "\n",
    "unique_errors = list(set(errors_by_alg[alg_name]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error type: RuntimeError: CUDA out of memory.\n",
      "num of unique errors with this string: 64 of 73\n",
      "error type: TimeoutException\n",
      "num of unique errors with this string: 9 of 73\n",
      "error type: Cannot allocate memory\n",
      "num of unique errors with this string: 0 of 73\n"
     ]
    }
   ],
   "source": [
    "# get some known errors out of the way\n",
    "\n",
    "known_err_str = [\n",
    "    \"RuntimeError: CUDA out of memory.\",\n",
    "    \"TimeoutException\",  # our timeout exception\n",
    "    \"Cannot allocate memory\",\n",
    "]\n",
    "\n",
    "for err_str in known_err_str:\n",
    "    print(f\"error type: {err_str}\")\n",
    "    print(f\"num of unique errors with this string: {len([e for e in unique_errors if err_str in e])} of {len(unique_errors)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 remaining errros\n"
     ]
    }
   ],
   "source": [
    "# what are the remaining errors?\n",
    "\n",
    "remaining_errors = [e for e in unique_errors if all([s not in e for s in known_err_str])]\n",
    "print(f\"{len(remaining_errors)} remaining errros\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = [e for e in unique_errors if \"CUDA out of memory\" in e]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/shared/tabzilla/TabSurvey/tabzilla_experiment.py\", line 137, in __call__\n",
      "    result = cross_validation(model, self.dataset, self.time_limit)\n",
      "  File \"/home/shared/tabzilla/TabSurvey/tabzilla_utils.py\", line 236, in cross_validation\n",
      "    loss_history, val_loss_history = curr_model.fit(\n",
      "  File \"/home/shared/tabzilla/TabSurvey/models/saint.py\", line 142, in fit\n",
      "    loss.backward()\n",
      "  File \"/opt/conda/envs/torch/lib/python3.10/site-packages/torch/_tensor.py\", line 363, in backward\n",
      "    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n",
      "  File \"/opt/conda/envs/torch/lib/python3.10/site-packages/torch/autograd/__init__.py\", line 173, in backward\n",
      "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "RuntimeError: CUDA out of memory. Tried to allocate 242.00 MiB (GPU 0; 14.76 GiB total capacity; 13.26 GiB already allocated; 43.75 MiB free; 13.65 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(es[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openml__Amazon_employee_access__34539\n",
      "openml__Click_prediction_small__190408\n",
      "openml__GesturePhaseSegmentationProcessed__14969\n",
      "openml__JapaneseVowels__3510\n",
      "openml__LED-display-domain-7digit__125921\n",
      "openml__Wine__190420\n",
      "openml__Wisconsin-breast-cancer-cytology-features__361003\n",
      "openml__adult-census__3953\n",
      "openml__arrhythmia__5\n",
      "openml__artificial-characters__14964\n",
      "openml__breast-cancer__145799\n",
      "openml__breast-w__15\n",
      "openml__california__361089\n",
      "openml__cjs__14967\n",
      "openml__cmc__23\n",
      "openml__dermatology__35\n",
      "openml__diabetes__37\n",
      "openml__dresses-sales__125920\n",
      "openml__ecoli__145977\n",
      "openml__eeg-eye-state__14951\n",
      "openml__eye_movements__3897\n",
      "openml__fertility__9984\n",
      "openml__glass__40\n",
      "openml__har__14970\n",
      "openml__heart-c__48\n",
      "openml__heart-h__50\n",
      "openml__ilpd__9971\n",
      "openml__ionosphere__145984\n",
      "openml__kin8nm__2280\n",
      "openml__kr-vs-kp__3\n",
      "openml__madelon__9976\n",
      "openml__nursery__9892\n",
      "openml__page-blocks__30\n",
      "openml__postoperative-patient-data__146210\n",
      "openml__profb__3561\n",
      "openml__semeion__9964\n",
      "openml__solar-flare__2068\n",
      "openml__tic-tac-toe__49\n",
      "openml__veteran__4828\n",
      "openml__vowel__3022\n",
      "openml__wdbc__9946\n",
      "openml__yeast__145793\n"
     ]
    }
   ],
   "source": [
    "# print(f\"datasets: {}\")\n",
    "\n",
    "\n",
    "d = list(errors_df[(errors_df['exception'].str.contains('CUDA out of memory')) & (errors_df['alg_name'] == 'SAINT')]['dataset_name'].unique())\n",
    "for i in d: print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# rtdl_FTTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of errors for alg rtdl_FTTransformer: 4057\n",
      "number of unique errors: 30\n"
     ]
    }
   ],
   "source": [
    "alg_name = \"rtdl_FTTransformer\"\n",
    "\n",
    "print(f\"number of errors for alg {alg_name}: {len(errors_by_alg[alg_name])}\")\n",
    "print(f\"number of unique errors: {len(set(errors_by_alg[alg_name]))}\")\n",
    "\n",
    "unique_errors = list(set(errors_by_alg[alg_name]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error type: RuntimeError: CUDA out of memory.\n",
      "num of unique errors with this string: 19 of 30\n",
      "error type: TimeoutException\n",
      "num of unique errors with this string: 0 of 30\n",
      "error type: Cannot allocate memory\n",
      "num of unique errors with this string: 0 of 30\n",
      "error type: If self.num_tokenizer is\n",
      "num of unique errors with this string: 2 of 30\n",
      "error type: If self.cat_tokenizer is\n",
      "num of unique errors with this string: 2 of 30\n",
      "error type: FileNotFoundError: [Errno 2] No such file or directory: \n",
      "num of unique errors with this string: 7 of 30\n"
     ]
    }
   ],
   "source": [
    "tmp_known_err_str = known_err_str + [\n",
    "    \"If self.num_tokenizer is\", # issue: https://github.com/naszilla/tabzilla/issues/84\n",
    "    \"If self.cat_tokenizer is\", # issue: https://github.com/naszilla/tabzilla/issues/84\n",
    "    \"FileNotFoundError: [Errno 2] No such file or directory: \",\n",
    "]\n",
    "\n",
    "for err_str in tmp_known_err_str:\n",
    "    print(f\"error type: {err_str}\")\n",
    "    print(f\"num of unique errors with this string: {len([e for e in unique_errors if err_str in e])} of {len(unique_errors)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 remaining errros\n"
     ]
    }
   ],
   "source": [
    "# what are the remaining errors?\n",
    "\n",
    "remaining_errors = [e for e in unique_errors if all([s not in e for s in tmp_known_err_str])]\n",
    "print(f\"{len(remaining_errors)} remaining errros\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of filenotfound errors: 3780\n",
      "algs: rtdl_FTTransformer    3780\n",
      "Name: alg_name, dtype: int64\n",
      "datasets: openml__APSFailure__168868    30\n",
      "openml__mushroom__24          30\n",
      "openml__poker-hand__9890      30\n",
      "openml__phoneme__9952         30\n",
      "openml__philippine__190410    30\n",
      "                              ..\n",
      "openml__dna__167140           30\n",
      "openml__dionis__189355        30\n",
      "openml__dilbert__168909       30\n",
      "openml__diabetes__37          30\n",
      "openml__yeast__145793         30\n",
      "Name: dataset_name, Length: 126, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "err_str = \"If self.\"\n",
    "print(f\"number of filenotfound errors: {len([e for e in errors_by_alg[alg_name] if err_str in e])}\")\n",
    "\n",
    "# which algs?\n",
    "print(f\"algs: {errors_df[errors_df['exception'].str.contains(err_str)]['alg_name'].value_counts()}\")\n",
    "\n",
    "# which datasets?\n",
    "print(f\"datasets: {errors_df[errors_df['exception'].str.contains(err_str)]['dataset_name'].value_counts()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openml__APSFailure__168868    30\n",
      "openml__mushroom__24          30\n",
      "openml__poker-hand__9890      30\n",
      "openml__phoneme__9952         30\n",
      "openml__philippine__190410    30\n",
      "                              ..\n",
      "openml__dna__167140           30\n",
      "openml__dionis__189355        30\n",
      "openml__dilbert__168909       30\n",
      "openml__diabetes__37          30\n",
      "openml__yeast__145793         30\n",
      "Name: dataset_name, Length: 126, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(errors_df[errors_df['exception'].str.contains(err_str)]['dataset_name'].value_counts())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DANet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of errors for alg DANet: 160\n",
      "number of unique errors: 12\n"
     ]
    }
   ],
   "source": [
    "alg_name = \"DANet\"\n",
    "\n",
    "print(f\"number of errors for alg {alg_name}: {len(errors_by_alg[alg_name])}\")\n",
    "print(f\"number of unique errors: {len(set(errors_by_alg[alg_name]))}\")\n",
    "\n",
    "unique_errors = list(set(errors_by_alg[alg_name]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error type: RuntimeError: CUDA out of memory.\n",
      "num of unique errors with this string: 0 of 12\n",
      "error type: TimeoutException\n",
      "num of unique errors with this string: 9 of 12\n",
      "error type: Cannot allocate memory\n",
      "num of unique errors with this string: 0 of 12\n",
      "error type: ValueError: Expected more than\n",
      "num of unique errors with this string: 3 of 12\n"
     ]
    }
   ],
   "source": [
    "tmp_known_err_str = known_err_str + [\n",
    "    \"ValueError: Expected more than\", # issue: https://github.com/naszilla/tabzilla/issues/84\n",
    "]\n",
    "\n",
    "\n",
    "for err_str in tmp_known_err_str:\n",
    "    print(f\"error type: {err_str}\")\n",
    "    print(f\"num of unique errors with this string: {len([e for e in unique_errors if err_str in e])} of {len(unique_errors)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 remaining errros\n"
     ]
    }
   ],
   "source": [
    "# what are the remaining errors?\n",
    "\n",
    "remaining_errors = [e for e in unique_errors if all([s not in e for s in tmp_known_err_str])]\n",
    "print(f\"{len(remaining_errors)} remaining errros\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # which datasets?\n",
    "# err_str = \"ValueError: Expected more than\"\n",
    "# print(f\"datasets: {errors_df[errors_df['exception'].str.contains(err_str)]['dataset_name'].value_counts()}\")\n",
    "\n",
    "# # which algs?\n",
    "# print(f\"algs: {errors_df[errors_df['exception'].str.contains(err_str)]['alg_name'].value_counts()}\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "367a26e3fad5ec8f1d0bebe9545860115b1157dbd92bed67faee9b31d4dbfaa5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
