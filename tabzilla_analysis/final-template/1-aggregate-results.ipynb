{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Aggregate results for analysis\n",
    "\n",
    "Read the complete metadataset and generate a clean version for analysis.\n",
    "\n",
    "\n",
    "## Instructions:\n",
    "1. make sure that the latest metadataset is present in the `TabSurvey` folder (two levels up from this script). The latest metadataset can be downloaded from the GCP bucket here: `tabzilla-results/metadatasets`.\n",
    "\n",
    "2. Run the first two cells in thie notebook, to create a metadataset `metadataset_df`. This dataframe includes all results from our experiments on datasets with clasisfication and binary targets. The remaining cells are divided into two sections: (A) and (B).\n",
    "\n",
    "3. Modify and run the cells in section (A) to create a dataframe `analysis_df`, which is a subset of `metadataset_df`. This subset should include all results you want to include in later analyses. Section (A) in this notebook selects results such that each algorithm has results for at least 85% of all datasets.\n",
    "\n",
    "4. After `analysis_df` is defined in section (A), run cells in section (B) to \"tune\" all algorithms on each dataset, and calculate normalized results and rankings. These cells create four \"cleaned\" results files, which will be used for all subsequent analysis: \n",
    "- `./cleaned_results/tuned_aggregated_results.csv`: performance of each tuned algorithm on each dataset, where performance is averaged over all 10 folds. \n",
    "- `./cleaned_results/tuned_fold_results.csv`: performance of each tuned algorithm on each dataset fold.\n",
    "- `./cleaned_results/tuned_aggregated_results_with_default.csv`: same as `tuned_aggregated_results_with_default.csv`, but with the default hyperparameters of each dataset included as a separate algorithm\n",
    "- `./cleaned_results/tuned_fold_results_with_default.csv`: same as `tuned_fold_results_with_default.csv`, but with the default hyperparameters of each dataset included as a separate algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from analysis_utils import get_tuned_alg_perf\n",
    "\n",
    "metadata_folder = Path(\"../../TabSurvey\")\n",
    "\n",
    "metadataset_df = pd.read_csv(metadata_folder / \"metadataset.csv\")\n",
    "errors_df = pd.read_csv(metadata_folder / \"metadataset_errors.csv\")\n",
    "\n",
    "# keep only binary and classification datasets. we have some results for regression datasets, which are not used.\n",
    "metadataset_df = metadataset_df.loc[metadataset_df[\"target_type\"].isin([\"binary\", \"classification\"]), :]\n",
    "\n",
    "# make sure that the cleaned_results folder exists\n",
    "output_folder = Path(\"./cleaned_results\")\n",
    "output_folder.mkdir(exist_ok=True)    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print number of results per dataset and alg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for each alg: number of datasets with results (out of 176)\n",
      "alg_name\n",
      "TabPFNModel            63\n",
      "NAM                    80\n",
      "DeepFM                 90\n",
      "TabTransformer        124\n",
      "SAINT                 138\n",
      "NODE                  141\n",
      "SVM                   143\n",
      "DANet                 147\n",
      "rtdl_FTTransformer    148\n",
      "VIME                  163\n",
      "STG                   164\n",
      "CatBoost              165\n",
      "LightGBM              165\n",
      "KNN                   167\n",
      "LinearModel           168\n",
      "TabNet                168\n",
      "RandomForest          173\n",
      "XGBoost               174\n",
      "rtdl_ResNet           174\n",
      "MLP                   175\n",
      "DecisionTree          175\n",
      "rtdl_MLP              176\n",
      "Name: dataset_name, dtype: int64\n",
      "for each dataset: number of algs with results (out of 22)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dataset_name\n",
       "openml__poker-hand__9890                                   5\n",
       "openml__covertype__7593                                    7\n",
       "openml__Devnagari-Script__167121                           8\n",
       "openml__albert__189356                                     9\n",
       "openml__CIFAR_10__167124                                  10\n",
       "openml__Fashion-MNIST__146825                             11\n",
       "openml__helena__168329                                    11\n",
       "openml__walking-activity__9945                            11\n",
       "openml__robert__168332                                    12\n",
       "openml__riccardo__168338                                  12\n",
       "openml__guillermo__168337                                 12\n",
       "openml__mnist_784__3573                                   12\n",
       "openml__Census-Income__168340                             12\n",
       "openml__airlines__189354                                  12\n",
       "openml__ldpa__9974                                        13\n",
       "openml__skin-segmentation__9965                           14\n",
       "openml__volkert__168331                                   14\n",
       "openml__MiniBooNE__168335                                 14\n",
       "openml__jungle_chess_2pcs_raw_endgame_complete__167119    14\n",
       "openml__jannis__168330                                    14\n",
       "openml__dilbert__168909                                   15\n",
       "openml__isolet__3481                                      15\n",
       "openml__fabert__168910                                    16\n",
       "openml__kropt__2076                                       16\n",
       "openml__har__14970                                        16\n",
       "openml__higgs__146606                                     16\n",
       "openml__connect-4__146195                                 16\n",
       "openml__shuttle__146212                                   16\n",
       "openml__gas-drift-different-concentrations__9987          16\n",
       "openml__chess__3952                                       16\n",
       "                                                          ..\n",
       "openml__ozone-level-8hr__9978                             21\n",
       "openml__jasmine__168911                                   21\n",
       "openml__jm1__3904                                         21\n",
       "openml__pc3__3903                                         21\n",
       "openml__Satellite__167211                                 21\n",
       "openml__hepatitis__54                                     21\n",
       "openml__Australian__146818                                22\n",
       "openml__breast-w__15                                      22\n",
       "openml__labor__4                                          22\n",
       "openml__irish__3543                                       22\n",
       "openml__ionosphere__145984                                22\n",
       "openml__ilpd__9971                                        22\n",
       "openml__wdbc__9946                                        22\n",
       "openml__hill-valley__145847                               22\n",
       "openml__acute-inflammations__10089                        22\n",
       "openml__colic__27                                         22\n",
       "openml__heart-c__48                                       22\n",
       "openml__colic__25                                         22\n",
       "openml__sonar__39                                         22\n",
       "openml__socmob__3797                                      22\n",
       "openml__credit-approval__29                               22\n",
       "openml__cylinder-bands__14954                             22\n",
       "openml__diabetes__37                                      22\n",
       "openml__fertility__9984                                   22\n",
       "openml__qsar-biodeg__9957                                 22\n",
       "openml__profb__3561                                       22\n",
       "openml__dresses-sales__125920                             22\n",
       "openml__pc1__3918                                         22\n",
       "openml__heart-h__50                                       22\n",
       "openml__kc2__3913                                         22\n",
       "Name: alg_name, Length: 176, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for each alg, for how many datasets are there results?\n",
    "print(f\"for each alg: number of datasets with results (out of {len(metadataset_df['dataset_name'].unique())})\")\n",
    "print(metadataset_df.groupby(\"alg_name\")[\"dataset_name\"].apply(lambda x: len(set(x))).sort_values())\n",
    "\n",
    "print(f\"for each dataset: number of algs with results (out of {len(metadataset_df['alg_name'].unique())})\")\n",
    "metadataset_df.groupby(\"dataset_name\")[\"alg_name\"].apply(lambda x: len(set(x))).sort_values()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A. Dataset inclusion/exclusion\n",
    "\n",
    "**Note:** Code in this section should create a dataframe called `analysis_df`, which is a subset of the dataframe `metadataset_df`, including only the results you want to use for the remaining analysis. Before running code in section (B) below, make sure that `analysis_df` is defined properly.\n",
    "\n",
    "**In this notebook,** we select results that meet the following criteria:\n",
    "1. every dataset needs to have results for at least 90% of all datasets\n",
    "2. we include every algorithm (so remove datasets until this criteria is met)\n",
    "\n",
    "To achieve these criteria, we remove datasets with the fewest results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for each dataset: number of algs with results\n",
      "dataset_name\n",
      "openml__poker-hand__9890             5\n",
      "openml__covertype__7593              7\n",
      "openml__Devnagari-Script__167121     8\n",
      "openml__albert__189356               9\n",
      "openml__CIFAR_10__167124            10\n",
      "Name: alg_name, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f\"for each dataset: number of algs with results\")\n",
    "alg_counts = metadataset_df.groupby(\"dataset_name\")[\"alg_name\"].agg(lambda x: len(set(x))).sort_values()\n",
    "print(alg_counts.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total num datasets: 176\n",
      "removing dataset 1: openml__poker-hand__9890 (total results: 5)\n",
      "min num datasets per alg: 138 (78.4090909090909%)\n",
      "total num datasets: 175\n",
      "removing dataset 2: openml__covertype__7593 (total results: 7)\n",
      "min num datasets per alg: 138 (78.85714285714286%)\n",
      "total num datasets: 174\n",
      "removing dataset 3: openml__Devnagari-Script__167121 (total results: 8)\n",
      "min num datasets per alg: 138 (79.3103448275862%)\n",
      "total num datasets: 173\n",
      "removing dataset 4: openml__albert__189356 (total results: 9)\n",
      "min num datasets per alg: 138 (79.76878612716763%)\n",
      "total num datasets: 172\n",
      "removing dataset 5: openml__CIFAR_10__167124 (total results: 10)\n",
      "min num datasets per alg: 138 (80.23255813953489%)\n",
      "total num datasets: 171\n",
      "removing dataset 6: openml__Fashion-MNIST__146825 (total results: 11)\n",
      "min num datasets per alg: 138 (80.70175438596492%)\n",
      "total num datasets: 170\n",
      "removing dataset 7: openml__helena__168329 (total results: 11)\n",
      "min num datasets per alg: 137 (80.58823529411765%)\n",
      "total num datasets: 169\n",
      "removing dataset 8: openml__walking-activity__9945 (total results: 11)\n",
      "min num datasets per alg: 137 (81.06508875739645%)\n",
      "total num datasets: 168\n",
      "removing dataset 9: openml__robert__168332 (total results: 12)\n",
      "min num datasets per alg: 137 (81.54761904761905%)\n",
      "total num datasets: 167\n",
      "removing dataset 10: openml__riccardo__168338 (total results: 12)\n",
      "min num datasets per alg: 137 (82.03592814371258%)\n",
      "total num datasets: 166\n",
      "removing dataset 11: openml__guillermo__168337 (total results: 12)\n",
      "min num datasets per alg: 137 (82.53012048192771%)\n",
      "total num datasets: 165\n",
      "removing dataset 12: openml__mnist_784__3573 (total results: 12)\n",
      "min num datasets per alg: 137 (83.03030303030303%)\n",
      "total num datasets: 164\n",
      "removing dataset 13: openml__Census-Income__168340 (total results: 12)\n",
      "min num datasets per alg: 137 (83.53658536585365%)\n",
      "total num datasets: 163\n",
      "removing dataset 14: openml__airlines__189354 (total results: 12)\n",
      "min num datasets per alg: 137 (84.04907975460122%)\n",
      "total num datasets: 162\n",
      "removing dataset 15: openml__ldpa__9974 (total results: 13)\n",
      "min num datasets per alg: 137 (84.5679012345679%)\n",
      "total num datasets: 161\n",
      "removing dataset 16: openml__skin-segmentation__9965 (total results: 14)\n",
      "min num datasets per alg: 136 (84.472049689441%)\n",
      "total num datasets: 160\n",
      "removing dataset 17: openml__volkert__168331 (total results: 14)\n",
      "min num datasets per alg: 136 (85.0%)\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "remove_datasets = []\n",
    "\n",
    "# drop:\n",
    "# - TabPFN (only runs for small datasets)\n",
    "# - NAM (lots of errors, long runtime)\n",
    "# - DeepFM (not implemented for multi-class)\n",
    "\n",
    "include_algs = [\n",
    "    \"SAINT\",\n",
    "    \"NODE\",\n",
    "    \"SVM\",\n",
    "    \"DANet\",\n",
    "    \"rtdl_FTTransformer\",\n",
    "    \"VIME\",\n",
    "    \"STG\",\n",
    "    \"CatBoost\",\n",
    "    \"LightGBM\",\n",
    "    \"KNN\",\n",
    "    \"LinearModel\",\n",
    "    \"TabNet\",\n",
    "    \"RandomForest\",\n",
    "    \"XGBoost\",\n",
    "    \"rtdl_ResNet\",\n",
    "    \"MLP\",\n",
    "    \"DecisionTree\",\n",
    "    \"rtdl_MLP\",\n",
    "    # \"NAM\",\n",
    "    # \"TabPFNModel\",\n",
    "    # \"DeepFM\",\n",
    "]\n",
    "\n",
    "test_df = metadataset_df.loc[metadataset_df[\"alg_name\"].isin(include_algs), :]\n",
    "\n",
    "for i in range(50):\n",
    "    total_datasets = len(test_df[\"dataset_name\"].unique())\n",
    "    print(f\"total num datasets: {total_datasets}\")\n",
    "    print(f\"removing dataset {i + 1}: {alg_counts.index[i]} (total results: {alg_counts.values[i]})\")\n",
    "    remove_datasets.append(alg_counts.index[i])\n",
    "    test_df = test_df.loc[~test_df[\"dataset_name\"].isin(remove_datasets), :]\n",
    "    # find alg with lowest num of datasets\n",
    "    dataset_counts = test_df.groupby(\"alg_name\")[\"dataset_name\"].agg(lambda x: len(set(x))).sort_values()\n",
    "    print(f\"min num datasets per alg: {dataset_counts.min()} ({100. * dataset_counts.min()/total_datasets}%)\")\n",
    "    if dataset_counts.min()/total_datasets >= 0.85: \n",
    "        print(\"done\")\n",
    "        break\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slightly more data prep\n",
    "\n",
    "Note: We will keep all algs, regardless of how many datasets they have results for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after removing datasets: number of datasets with results\n",
      "alg_name\n",
      "NODE                  136\n",
      "SAINT                 137\n",
      "SVM                   142\n",
      "rtdl_FTTransformer    143\n",
      "DANet                 146\n",
      "CatBoost              155\n",
      "LightGBM              156\n",
      "LinearModel           156\n",
      "STG                   156\n",
      "VIME                  158\n",
      "RandomForest          158\n",
      "MLP                   158\n",
      "KNN                   158\n",
      "rtdl_ResNet           158\n",
      "TabNet                159\n",
      "XGBoost               159\n",
      "DecisionTree          159\n",
      "rtdl_MLP              159\n",
      "Name: dataset_name, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "analysis_df = test_df\n",
    "\n",
    "print(\"after removing datasets: number of datasets with results\")\n",
    "dataset_counts = analysis_df.groupby(\"alg_name\")[\"dataset_name\"].agg(lambda x: len(set(x))).sort_values()\n",
    "print(dataset_counts)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B. Tune and rank algorithms for each dataset\n",
    "\n",
    "**Note**: At this point, you should have a dataframe called `analysis_df`, which contains all results you want to include in the remainder of the analysis. \n",
    "\n",
    "The code below performs hyperparameter tuning & ranking of each alg, and writes four cleaned results files to the directory `./cleaned_results`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_list = [\n",
    "    \"Accuracy\",\n",
    "    \"F1\",\n",
    "    \"Log Loss\",\n",
    "]\n",
    "\n",
    "obj_type_list = [\n",
    "    \"maximize\",\n",
    "    \"maximize\",\n",
    "    \"minimize\",\n",
    "]\n",
    "result_df_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bookkeeping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace alg name with display name\n",
    "from analysis_utils import ALG_DISPLAY_NAMES, ALG_TYPES\n",
    "analysis_df.loc[:, \"alg_name\"] = analysis_df[\"alg_name\"].apply(lambda x: ALG_DISPLAY_NAMES[x])\n",
    "\n",
    "# add alg type\n",
    "analysis_df.loc[:, \"alg_type\"] = analysis_df[\"alg_name\"].apply(lambda x: ALG_TYPES[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a copy of each \"default\" hparam row, to treat this as a separate alg\n",
    "default_rows = analysis_df.loc[analysis_df[\"hparam_source\"] == \"default\"].copy()\n",
    "default_rows.loc[:, \"alg_name\"] = default_rows[\"alg_name\"].apply(lambda x: x + \" (default)\")\n",
    "\n",
    "# remove TabPFN and LinearModel, since these only have one hparam set\n",
    "default_rows = default_rows.loc[~(default_rows[\"alg_name\"].str.contains(\"TabPFNModel\") | default_rows[\"alg_name\"].str.contains(\"LinearModel\")), :]\n",
    "\n",
    "# append these to the metadataset\n",
    "analysis_df_with_default = pd.concat([analysis_df, default_rows], ignore_index=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### produce cleaned results files\n",
    "\n",
    "first, each algorithm is tuned for each dataset fold (10 folds per dataset), using all available hyperparameter samples. we then calculate the normalized and ranked performance for each algorithm over all datasets.\n",
    "\n",
    "the following loop produces four files:\n",
    "- `./cleaned_results/tuned_aggregated_results.csv`: performance of each tuned algorithm on each dataset, where performance is averaged over all 10 folds. \n",
    "- `./cleaned_results/tuned_fold_results.csv`: performance of each tuned algorithm on each dataset fold.\n",
    "- `./cleaned_results/tuned_aggregated_results_with_default.csv`: same as `tuned_aggregated_results_with_default.csv`, but with the default hyperparameters of each dataset included as a separate algorithm\n",
    "- `./cleaned_results/tuned_fold_results_with_default.csv`: same as `tuned_fold_results_with_default.csv`, but with the default hyperparameters of each dataset included as a separate algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_result_dfs = {}\n",
    "for drop_default in [True, False]:\n",
    "    for i, (metric, objective_type) in enumerate(zip(metric_list, obj_type_list)):\n",
    "\n",
    "        test_metric_col = metric + \"__test\"\n",
    "\n",
    "        if drop_default:\n",
    "            df = analysis_df.copy()\n",
    "        else:\n",
    "            df = analysis_df_with_default.copy()\n",
    "\n",
    "        tuned_alg_perf = get_tuned_alg_perf(df, metric=metric)\n",
    "\n",
    "        # NOTE: this \"tunes\" each algorithm for each training fold separately. so each of the 10 folds might use different hparams.\n",
    "        tuned_result_dfs[metric] = tuned_alg_perf\n",
    "\n",
    "        ##############################\n",
    "        ### STEP 1: TREAT EACH FOLD AS SEPARATE DATASET\n",
    "\n",
    "        result_col = test_metric_col\n",
    "        \n",
    "        # for each dataset, find the min and max metrics over all tuned algs\n",
    "        overall_bounds = tuned_alg_perf.groupby(\"dataset_fold_id\").agg({result_col: [\"min\", \"max\"]}).reset_index()\n",
    "\n",
    "        # rename the multiindex cols\n",
    "        new_cols = []\n",
    "        for c in overall_bounds.columns:\n",
    "            if c[1] == \"\":\n",
    "                new_cols.append(c[0])\n",
    "            else:\n",
    "                new_cols.append(\"_\".join(c))\n",
    "\n",
    "        overall_bounds.columns = new_cols\n",
    "\n",
    "        tuned_alg_perf = tuned_alg_perf.merge(overall_bounds, on=\"dataset_fold_id\", how=\"left\")\n",
    "\n",
    "        # add normalized metric\n",
    "        tuned_alg_perf.loc[:, \"normalized_\" + result_col] = (tuned_alg_perf[result_col] - tuned_alg_perf[result_col + \"_min\"]) / (tuned_alg_perf[result_col + \"_max\"] - tuned_alg_perf[result_col + \"_min\"])\n",
    "\n",
    "        # rank all algs for each dataset\n",
    "        ascending = False if objective_type == \"maximize\" else True\n",
    "        \n",
    "        tuned_alg_perf.loc[:, f\"{metric}_rank\"] = tuned_alg_perf.groupby([\"dataset_fold_id\"])[result_col].rank(method=\"min\", ascending=ascending).values\n",
    "\n",
    "        # keep these cols to merge\n",
    "        merge_cols = [\n",
    "            \"alg_name\", \n",
    "            \"dataset_fold_id\", \n",
    "            \"normalized_\" + result_col,\n",
    "            f\"{metric}_rank\",\n",
    "            result_col + \"_min\",\n",
    "            result_col + \"_max\"\n",
    "        ]\n",
    "\n",
    "        if i == 0:\n",
    "            fold_tuned_df = tuned_alg_perf.copy()\n",
    "        else:\n",
    "            fold_tuned_df = fold_tuned_df.merge(tuned_alg_perf[merge_cols], on=[\"alg_name\", \"dataset_fold_id\"])\n",
    "\n",
    "        ##############################\n",
    "        ### STEP 2: AVERAGE OVER FOLDS\n",
    "\n",
    "        if i == 0:\n",
    "            agg_dict = {\n",
    "                test_metric_col: [\"median\", \"mean\"],\n",
    "                \"time__train\": [\"median\", \"mean\"],\n",
    "                # \"dataset_name\": [\"count\"],\n",
    "            }\n",
    "        else:\n",
    "            agg_dict = {\n",
    "                test_metric_col: [\"median\", \"mean\"],\n",
    "            }\n",
    "\n",
    "        # aggregate over folds: take the mean & median performance over each fold\n",
    "        agg_tuned_alg_perf = tuned_alg_perf.groupby([\"alg_name\", \"dataset_name\"]).agg(agg_dict).reset_index()\n",
    "\n",
    "        # rename the multiindex cols\n",
    "        new_cols = []\n",
    "        for c in agg_tuned_alg_perf.columns:\n",
    "            if c[1] == \"\":\n",
    "                new_cols.append(c[0])\n",
    "            else:\n",
    "                new_cols.append(\"_\".join(c))\n",
    "\n",
    "        agg_tuned_alg_perf.columns = new_cols\n",
    "\n",
    "\n",
    "        # define the target metric column, we will use this value for all plots\n",
    "        result_col = test_metric_col + \"_mean\"\n",
    "\n",
    "        # for each dataset, find the min and max metrics over all tuned algs\n",
    "        overall_bounds = agg_tuned_alg_perf.groupby(\"dataset_name\").agg({result_col: [\"min\", \"max\"]}).reset_index()\n",
    "        \n",
    "        # rename the multiindex cols\n",
    "        new_cols = []\n",
    "        for c in overall_bounds.columns:\n",
    "            if c[1] == \"\":\n",
    "                new_cols.append(c[0])\n",
    "            else:\n",
    "                new_cols.append(\"_\".join(c))\n",
    "\n",
    "        overall_bounds.columns = new_cols\n",
    "\n",
    "        \n",
    "        agg_tuned_alg_perf = agg_tuned_alg_perf.merge(overall_bounds, on=\"dataset_name\", how=\"left\")\n",
    "\n",
    "        # add normalized metric\n",
    "        agg_tuned_alg_perf.loc[:, \"normalized_\" + result_col] = (agg_tuned_alg_perf[result_col] - agg_tuned_alg_perf[result_col + \"_min\"]) / (agg_tuned_alg_perf[result_col + \"_max\"] - agg_tuned_alg_perf[result_col + \"_min\"])\n",
    "\n",
    "        # rank all algs for each dataset\n",
    "        ascending = False if objective_type == \"maximize\" else True\n",
    "        \n",
    "        # rank according to mean performance over all folds\n",
    "        agg_method = \"mean\"\n",
    "\n",
    "        # rank everything\n",
    "        agg_tuned_alg_perf.loc[:, f\"{metric}_rank_{agg_method}\"]  = \\\n",
    "            agg_tuned_alg_perf.groupby([\"dataset_name\"])[test_metric_col + \"_\" + agg_method].rank(method=\"min\", ascending=ascending).values\n",
    "\n",
    "\n",
    "        # keep these cols to merge\n",
    "        merge_cols = [\n",
    "            \"alg_name\", \n",
    "            \"dataset_name\",\n",
    "            \"normalized_\" + result_col,\n",
    "            f\"{metric}_rank_mean\",\n",
    "            result_col + \"_min\",\n",
    "            result_col + \"_max\"\n",
    "        ]\n",
    "\n",
    "        if i == 0:\n",
    "            tuned_agg_df = agg_tuned_alg_perf.copy()\n",
    "        else:\n",
    "            tuned_agg_df = tuned_agg_df.merge(agg_tuned_alg_perf[merge_cols], on=[\"alg_name\", \"dataset_name\"])\n",
    "\n",
    "    # save results\n",
    "\n",
    "    # merge in alg type, for bookkeeping\n",
    "    alg_type_df = analysis_df[[\"alg_name\", \"alg_type\"]].drop_duplicates()\n",
    "    tuned_agg_df = tuned_agg_df.merge(alg_type_df, on=\"alg_name\", how=\"left\")\n",
    "    fold_tuned_df = fold_tuned_df.merge(alg_type_df, on=\"alg_name\", how=\"left\")\n",
    "\n",
    "    if drop_default:\n",
    "        agg_df_no_default = tuned_agg_df.copy()\n",
    "        agg_df_no_default.to_csv(\"./cleaned_results/tuned_aggregated_results.csv\")\n",
    "\n",
    "        tuned_fold_df_no_default = fold_tuned_df.copy()\n",
    "        tuned_fold_df_no_default.to_csv(\"./cleaned_results/tuned_fold_results.csv\")\n",
    "       \n",
    "    else:\n",
    "        agg_df_with_default = tuned_agg_df.copy()\n",
    "        agg_df_with_default.to_csv(\"./cleaned_results/tuned_aggregated_results_with_default.csv\")\n",
    "\n",
    "        tuned_fold_df_with_default = fold_tuned_df.copy()\n",
    "        tuned_fold_df_with_default.to_csv(\"./cleaned_results/tuned_fold_results_with_default.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alg_name</th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>Accuracy__test_median</th>\n",
       "      <th>Accuracy__test_mean</th>\n",
       "      <th>time__train_median</th>\n",
       "      <th>time__train_mean</th>\n",
       "      <th>Accuracy__test_mean_min</th>\n",
       "      <th>Accuracy__test_mean_max</th>\n",
       "      <th>normalized_Accuracy__test_mean</th>\n",
       "      <th>Accuracy_rank_mean</th>\n",
       "      <th>normalized_F1__test_mean</th>\n",
       "      <th>F1_rank_mean</th>\n",
       "      <th>F1__test_mean_min</th>\n",
       "      <th>F1__test_mean_max</th>\n",
       "      <th>normalized_Log Loss__test_mean</th>\n",
       "      <th>Log Loss_rank_mean</th>\n",
       "      <th>Log Loss__test_mean_min</th>\n",
       "      <th>Log Loss__test_mean_max</th>\n",
       "      <th>alg_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>openml__APSFailure__168868</td>\n",
       "      <td>0.994145</td>\n",
       "      <td>0.994013</td>\n",
       "      <td>6.412328</td>\n",
       "      <td>7.276401</td>\n",
       "      <td>0.970303</td>\n",
       "      <td>0.994500</td>\n",
       "      <td>0.979880</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.979880</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.970303</td>\n",
       "      <td>0.994500</td>\n",
       "      <td>0.002362</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.017652</td>\n",
       "      <td>0.562957</td>\n",
       "      <td>gbdt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>openml__Amazon_employee_access__34539</td>\n",
       "      <td>0.946903</td>\n",
       "      <td>0.947359</td>\n",
       "      <td>1.708439</td>\n",
       "      <td>1.729567</td>\n",
       "      <td>0.941957</td>\n",
       "      <td>0.951570</td>\n",
       "      <td>0.561901</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.561901</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.941957</td>\n",
       "      <td>0.951570</td>\n",
       "      <td>0.003507</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.155615</td>\n",
       "      <td>0.364447</td>\n",
       "      <td>gbdt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>openml__Australian__146818</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.872464</td>\n",
       "      <td>1.347650</td>\n",
       "      <td>1.393643</td>\n",
       "      <td>0.711594</td>\n",
       "      <td>0.872464</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.711594</td>\n",
       "      <td>0.872464</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.302677</td>\n",
       "      <td>0.755920</td>\n",
       "      <td>gbdt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>openml__Bioresponse__9910</td>\n",
       "      <td>0.798940</td>\n",
       "      <td>0.795521</td>\n",
       "      <td>5.815126</td>\n",
       "      <td>6.748842</td>\n",
       "      <td>0.736600</td>\n",
       "      <td>0.796848</td>\n",
       "      <td>0.977987</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.977987</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.736600</td>\n",
       "      <td>0.796848</td>\n",
       "      <td>0.025096</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.451718</td>\n",
       "      <td>0.626404</td>\n",
       "      <td>gbdt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>openml__Click_prediction_small__190408</td>\n",
       "      <td>0.839655</td>\n",
       "      <td>0.838565</td>\n",
       "      <td>14.031593</td>\n",
       "      <td>16.126213</td>\n",
       "      <td>0.831581</td>\n",
       "      <td>0.838565</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.831581</td>\n",
       "      <td>0.838565</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.409856</td>\n",
       "      <td>5.816984</td>\n",
       "      <td>gbdt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alg_name                            dataset_name  Accuracy__test_median  \\\n",
       "0  CatBoost              openml__APSFailure__168868               0.994145   \n",
       "1  CatBoost   openml__Amazon_employee_access__34539               0.946903   \n",
       "2  CatBoost              openml__Australian__146818               0.869565   \n",
       "3  CatBoost               openml__Bioresponse__9910               0.798940   \n",
       "4  CatBoost  openml__Click_prediction_small__190408               0.839655   \n",
       "\n",
       "   Accuracy__test_mean  time__train_median  time__train_mean  \\\n",
       "0             0.994013            6.412328          7.276401   \n",
       "1             0.947359            1.708439          1.729567   \n",
       "2             0.872464            1.347650          1.393643   \n",
       "3             0.795521            5.815126          6.748842   \n",
       "4             0.838565           14.031593         16.126213   \n",
       "\n",
       "   Accuracy__test_mean_min  Accuracy__test_mean_max  \\\n",
       "0                 0.970303                 0.994500   \n",
       "1                 0.941957                 0.951570   \n",
       "2                 0.711594                 0.872464   \n",
       "3                 0.736600                 0.796848   \n",
       "4                 0.831581                 0.838565   \n",
       "\n",
       "   normalized_Accuracy__test_mean  Accuracy_rank_mean  \\\n",
       "0                        0.979880                 3.0   \n",
       "1                        0.561901                 4.0   \n",
       "2                        1.000000                 1.0   \n",
       "3                        0.977987                 2.0   \n",
       "4                        1.000000                 1.0   \n",
       "\n",
       "   normalized_F1__test_mean  F1_rank_mean  F1__test_mean_min  \\\n",
       "0                  0.979880           3.0           0.970303   \n",
       "1                  0.561901           4.0           0.941957   \n",
       "2                  1.000000           1.0           0.711594   \n",
       "3                  0.977987           2.0           0.736600   \n",
       "4                  1.000000           1.0           0.831581   \n",
       "\n",
       "   F1__test_mean_max  normalized_Log Loss__test_mean  Log Loss_rank_mean  \\\n",
       "0           0.994500                        0.002362                 3.0   \n",
       "1           0.951570                        0.003507                 2.0   \n",
       "2           0.872464                        0.000000                 1.0   \n",
       "3           0.796848                        0.025096                 3.0   \n",
       "4           0.838565                        0.000000                 1.0   \n",
       "\n",
       "   Log Loss__test_mean_min  Log Loss__test_mean_max alg_type  \n",
       "0                 0.017652                 0.562957     gbdt  \n",
       "1                 0.155615                 0.364447     gbdt  \n",
       "2                 0.302677                 0.755920     gbdt  \n",
       "3                 0.451718                 0.626404     gbdt  \n",
       "4                 0.409856                 5.816984     gbdt  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take a peek\n",
    "agg_df_no_default.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "367a26e3fad5ec8f1d0bebe9545860115b1157dbd92bed67faee9b31d4dbfaa5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
